{"ast":null,"code":"'use strict';\n\nmodule.exports = text;\n\nfunction text(eat, value, silent) {\n  var self = this;\n  var methods;\n  var tokenizers;\n  var index;\n  var length;\n  var subvalue;\n  var position;\n  var tokenizer;\n  var name;\n  var min;\n  var now;\n  /* istanbul ignore if - never used (yet) */\n\n  if (silent) {\n    return true;\n  }\n\n  methods = self.inlineMethods;\n  length = methods.length;\n  tokenizers = self.inlineTokenizers;\n  index = -1;\n  min = value.length;\n\n  while (++index < length) {\n    name = methods[index];\n\n    if (name === 'text' || !tokenizers[name]) {\n      continue;\n    }\n\n    tokenizer = tokenizers[name].locator;\n\n    if (!tokenizer) {\n      eat.file.fail('Missing locator: `' + name + '`');\n    }\n\n    position = tokenizer.call(self, value, 1);\n\n    if (position !== -1 && position < min) {\n      min = position;\n    }\n  }\n\n  subvalue = value.slice(0, min);\n  now = eat.now();\n  self.decode(subvalue, now, function (content, position, source) {\n    eat(source || content)({\n      type: 'text',\n      value: content\n    });\n  });\n}","map":{"version":3,"sources":["/projects/testswap/uniswap-interface/node_modules/remark-parse/lib/tokenize/text.js"],"names":["module","exports","text","eat","value","silent","self","methods","tokenizers","index","length","subvalue","position","tokenizer","name","min","now","inlineMethods","inlineTokenizers","locator","file","fail","call","slice","decode","content","source","type"],"mappings":"AAAA;;AAEAA,MAAM,CAACC,OAAP,GAAiBC,IAAjB;;AAEA,SAASA,IAAT,CAAcC,GAAd,EAAmBC,KAAnB,EAA0BC,MAA1B,EAAkC;AAChC,MAAIC,IAAI,GAAG,IAAX;AACA,MAAIC,OAAJ;AACA,MAAIC,UAAJ;AACA,MAAIC,KAAJ;AACA,MAAIC,MAAJ;AACA,MAAIC,QAAJ;AACA,MAAIC,QAAJ;AACA,MAAIC,SAAJ;AACA,MAAIC,IAAJ;AACA,MAAIC,GAAJ;AACA,MAAIC,GAAJ;AAEA;;AACA,MAAIX,MAAJ,EAAY;AACV,WAAO,IAAP;AACD;;AAEDE,EAAAA,OAAO,GAAGD,IAAI,CAACW,aAAf;AACAP,EAAAA,MAAM,GAAGH,OAAO,CAACG,MAAjB;AACAF,EAAAA,UAAU,GAAGF,IAAI,CAACY,gBAAlB;AACAT,EAAAA,KAAK,GAAG,CAAC,CAAT;AACAM,EAAAA,GAAG,GAAGX,KAAK,CAACM,MAAZ;;AAEA,SAAO,EAAED,KAAF,GAAUC,MAAjB,EAAyB;AACvBI,IAAAA,IAAI,GAAGP,OAAO,CAACE,KAAD,CAAd;;AAEA,QAAIK,IAAI,KAAK,MAAT,IAAmB,CAACN,UAAU,CAACM,IAAD,CAAlC,EAA0C;AACxC;AACD;;AAEDD,IAAAA,SAAS,GAAGL,UAAU,CAACM,IAAD,CAAV,CAAiBK,OAA7B;;AAEA,QAAI,CAACN,SAAL,EAAgB;AACdV,MAAAA,GAAG,CAACiB,IAAJ,CAASC,IAAT,CAAc,uBAAuBP,IAAvB,GAA8B,GAA5C;AACD;;AAEDF,IAAAA,QAAQ,GAAGC,SAAS,CAACS,IAAV,CAAehB,IAAf,EAAqBF,KAArB,EAA4B,CAA5B,CAAX;;AAEA,QAAIQ,QAAQ,KAAK,CAAC,CAAd,IAAmBA,QAAQ,GAAGG,GAAlC,EAAuC;AACrCA,MAAAA,GAAG,GAAGH,QAAN;AACD;AACF;;AAEDD,EAAAA,QAAQ,GAAGP,KAAK,CAACmB,KAAN,CAAY,CAAZ,EAAeR,GAAf,CAAX;AACAC,EAAAA,GAAG,GAAGb,GAAG,CAACa,GAAJ,EAAN;AAEAV,EAAAA,IAAI,CAACkB,MAAL,CAAYb,QAAZ,EAAsBK,GAAtB,EAA2B,UAAUS,OAAV,EAAmBb,QAAnB,EAA6Bc,MAA7B,EAAqC;AAC9DvB,IAAAA,GAAG,CAACuB,MAAM,IAAID,OAAX,CAAH,CAAuB;AACrBE,MAAAA,IAAI,EAAE,MADe;AAErBvB,MAAAA,KAAK,EAAEqB;AAFc,KAAvB;AAID,GALD;AAMD","sourcesContent":["'use strict';\n\nmodule.exports = text;\n\nfunction text(eat, value, silent) {\n  var self = this;\n  var methods;\n  var tokenizers;\n  var index;\n  var length;\n  var subvalue;\n  var position;\n  var tokenizer;\n  var name;\n  var min;\n  var now;\n\n  /* istanbul ignore if - never used (yet) */\n  if (silent) {\n    return true;\n  }\n\n  methods = self.inlineMethods;\n  length = methods.length;\n  tokenizers = self.inlineTokenizers;\n  index = -1;\n  min = value.length;\n\n  while (++index < length) {\n    name = methods[index];\n\n    if (name === 'text' || !tokenizers[name]) {\n      continue;\n    }\n\n    tokenizer = tokenizers[name].locator;\n\n    if (!tokenizer) {\n      eat.file.fail('Missing locator: `' + name + '`');\n    }\n\n    position = tokenizer.call(self, value, 1);\n\n    if (position !== -1 && position < min) {\n      min = position;\n    }\n  }\n\n  subvalue = value.slice(0, min);\n  now = eat.now();\n\n  self.decode(subvalue, now, function (content, position, source) {\n    eat(source || content)({\n      type: 'text',\n      value: content\n    });\n  });\n}\n"]},"metadata":{},"sourceType":"script"}